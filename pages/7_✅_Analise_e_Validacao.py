import streamlit as st
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, roc_auc_score
import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

def main():
    st.title("‚úÖ An√°lise e Valida√ß√£o do Modelo")
    st.markdown("""
    Entenda **como o seu modelo se comporta na pr√°tica** com m√©tricas essenciais para credit scoring.  
    Aqui voc√™ vai aprender o que cada indicador significa ‚Äî e por que ele importa.
    """)

    if 'modelo' not in st.session_state:
        st.warning("Nenhum modelo treinado! Construa um modelo primeiro.")
        st.page_link("pages/6_ü§ñ_Modelagem.py", label="‚Üí Ir para Modelagem", icon="ü§ñ")
        return

    X_test = st.session_state.get('X_test')
    y_test = st.session_state.get('y_test')

    if X_test is None or y_test is None:
        st.error("Dados de teste n√£o dispon√≠veis. Treine o modelo novamente.")
        return

    model = st.session_state.modelo
    y_pred = model.predict(X_test)

    # Probabilidades (necess√°rias para ROC e KS)
    try:
        y_proba = model.predict_proba(X_test)[:, 1]  # Probabilidade de classe 1 (inadimplente)
    except:
        st.warning("O modelo n√£o suporta `predict_proba`. Usando predi√ß√£o direta.")
        y_proba = y_pred

    # --- 1. MATRIZ DE CONFUS√ÉO ---
    st.markdown("### üìä Matriz de Confus√£o")
    st.info("""
    Mostra os acertos e erros do modelo. Ajuda a entender **quem foi classificado corretamente**.
    - **VP (Verdadeiro Positivo)**: Inadimplente ‚Üí previsto como inadimplente ‚úÖ  
    - **VN (Verdadeiro Negativo)**: Adimplente ‚Üí previsto como adimplente ‚úÖ  
    - **FP (Falso Positivo)**: Adimplente ‚Üí previsto como inadimplente ‚ùå (rejei√ß√£o injusta)  
    - **FN (Falso Negativo)**: Inadimplente ‚Üí previsto como adimplente ‚ùå (pior erro: risco n√£o detectado)
    """)

    cm = confusion_matrix(y_test, y_pred)
    fig, ax = plt.subplots(figsize=(2.5, 2))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,
                xticklabels=['Adimplente (0)', 'Inadimplente (1)'],
                yticklabels=['Adimplente (0)', 'Inadimplente (1)'])
    ax.set_ylabel('Real')
    ax.set_xlabel('Previsto')
    ax.set_title('Matriz de Confus√£o')
    st.pyplot(fig)

    # --- 2. RELAT√ìRIO DE CLASSIFICA√á√ÉO AMIG√ÅVEL ---
    st.markdown("### üß† Relat√≥rio de Classifica√ß√£o (Explicado)")
    st.info("""
    Abaixo, cada m√©trica √© explicada com base em um cen√°rio de concess√£o de cr√©dito.  
    Imagine que o modelo decide **a quem emprestar dinheiro**.
    """)

    # Calcula m√©tricas
    tn, fp, fn, tp = cm.ravel()
    precision = tp / (tp + fp) if (tp + fp) > 0 else 0
    recall = tp / (tp + fn) if (tp + fn) > 0 else 0
    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
    accuracy = (tp + tn) / (tp + tn + fp + fn)

    # Tabela de m√©tricas
    metricas_df = pd.DataFrame({
        "M√©trica": ["Precision", "Recall", "F1-Score", "Acur√°cia"],
        "Valor": [f"{precision:.2%}", f"{recall:.2%}", f"{f1:.2%}", f"{accuracy:.2%}"],
        "Explica√ß√£o": [
            "**Precision (Precis√£o)**: Entre todos os clientes marcados como 'inadimplentes', quantos realmente s√£o? Alta precis√£o = poucos falsos positivos (n√£o rejeitamos bons clientes por engano).",
            "**Recall (Sensibilidade)**: Dos verdadeiros inadimplentes, quantos o modelo conseguiu identificar? Alto recall = poucos falsos negativos (capturamos mais risco).",
            "**F1-Score**: M√©dia harm√¥nica entre Precision e Recall. √ìtimo quando queremos equil√≠brio entre capturar risco e n√£o rejeitar bons clientes.",
            "**Acur√°cia**: Propor√ß√£o total de acertos. Pode ser enganosa se a base for desbalanceada (ex: 95% adimplentes)."
        ]
    })

    for _, row in metricas_df.iterrows():
        st.markdown(f"#### {row['M√©trica']} ‚Üí `{row['Valor']}`")
        st.markdown(row['Explica√ß√£o'])
        st.markdown("---")

    # --- 3. CURVA ROC e AUROC ---
    st.markdown("### üìà Curva ROC e AUC")
    st.info("""
    A **Curva ROC** mostra o trade-off entre **verdadeiros positivos (Recall)** e **falsos positivos** em diferentes limiares.
    - **AUC (√Årea sob a curva)**: Quanto maior, melhor o modelo separa bons e maus pagadores.
    - **AUC > 0.7**: razo√°vel | **> 0.8**: bom | **> 0.9**: excelente
    """)

    fpr, tpr, _ = roc_curve(y_test, y_proba)
    roc_auc = auc(fpr, tpr)

    fig, ax = plt.subplots(figsize=(6, 5))
    ax.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC (AUC = {roc_auc:.2f})')
    ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Aleat√≥rio (AUC = 0.5)')
    ax.set_xlim([0.0, 1.0])
    ax.set_ylim([0.0, 1.05])
    ax.set_xlabel('Taxa de Falsos Positivos (1 - Especificidade)')
    ax.set_ylabel('Taxa de Verdadeiros Positivos (Recall)')
    ax.set_title('Curva ROC')
    ax.legend(loc="lower right")
    st.pyplot(fig)

    st.metric("AUC (ROC)", f"{roc_auc:.2f}")

    # --- 4. TESTE KS (Kolmogorov-Smirnov) ---
    st.markdown("### üìä Estat√≠stica KS")
    st.info("""
    O **KS** mede a maior separa√ß√£o entre a distribui√ß√£o acumulada de **bons** e **maus pagadores**.
    - **KS > 0.3**: bom poder de separa√ß√£o
    - **KS > 0.4**: excelente
    √â uma m√©trica muito usada em cr√©dito porque mostra claramente o poder discriminat√≥rio do modelo.
    """)

    # Distribui√ß√£o acumulada
    thresholds = np.linspace(0, 1, 100)
    tpr_ks = [np.mean(y_proba[y_test == 1] >= th) for th in thresholds]
    fpr_ks = [np.mean(y_proba[y_test == 0] >= th) for th in thresholds]
    ks_values = [t - f for t, f in zip(tpr_ks, fpr_ks)]
    ks_max = max(ks_values)
    best_th = thresholds[np.argmax(ks_values)]

    fig, ax = plt.subplots(figsize=(6, 4))
    ax.plot(thresholds, tpr_ks, label='Bons (TPR)', color='green')
    ax.plot(thresholds, fpr_ks, label='Maus (FPR)', color='red')
    ax.plot(thresholds, ks_values, label='KS (diferen√ßa)', color='blue', linestyle='--')
    ax.axvline(best_th, color='gray', linestyle=':', label=f'Limiar √≥timo (KS): {best_th:.2f}')
    ax.set_xlabel('Limiar de decis√£o')
    ax.set_ylabel('Taxa acumulada')
    ax.set_title('An√°lise KS')
    ax.legend()
    st.pyplot(fig)

    st.metric("KS M√°ximo", f"{ks_max:.2f}")
    st.caption(f"Limiar √≥timo para KS: {best_th:.2f}")

    # --- 5. AN√ÅLISE DE OVERFITTING (Curva de Perda) ---
    st.markdown("### üìâ An√°lise de Overfitting: Curva de Perda")
    st.info("""
    **Overfitting** ocorre quando o modelo "decora" os dados de treino, mas falha em generalizar para novos dados.  
    A **curva de perda** mostra o desempenho do modelo no treino e no teste ao longo do tempo (ou de itera√ß√µes).  
    Se a curva de treino continua melhorando, mas a do teste estabiliza ou piora, √© sinal de overfitting.
    """)
    
    # Simula√ß√£o de curva de perda (j√° que sklearn n√£o fornece diretamente)
    try:
        from sklearn.model_selection import validation_curve
        from sklearn.linear_model import LogisticRegression
        import numpy as np
    
        # Usamos um modelo similar para simular a curva (apenas para fins did√°ticos)
        if modelo_tipo == "Random Forest":
            from sklearn.ensemble import RandomForestClassifier
            model_for_curve = RandomForestClassifier(max_depth=10, random_state=42)
            param_range = np.arange(1, 11)
            train_scores, test_scores = validation_curve(
                model_for_curve, X_test, y_test, param_name="max_depth", param_range=param_range,
                cv=3, scoring="accuracy", n_jobs=-1
            )
            xlabel = "Profundidade da √Årvore (max_depth)"
            title = "Curva de Valida√ß√£o - Random Forest"
        else:
            model_for_curve = LogisticRegression(solver='liblinear', max_iter=1000)
            param_range = [0.001, 0.01, 0.1, 1, 10]
            train_scores, test_scores = validation_curve(
                model_for_curve, X_test, y_test, param_name="C", param_range=param_range,
                cv=3, scoring="accuracy", n_jobs=-1
            )
            xlabel = "Par√¢metro de Regulariza√ß√£o (C)"
            title = "Curva de Valida√ß√£o - Regress√£o Log√≠stica"
    
        # M√©dia e desvio
        train_mean = np.mean(train_scores, axis=1)
        train_std = np.std(train_scores, axis=1)
        test_mean = np.mean(test_scores, axis=1)
        test_std = np.std(test_scores, axis=1)
    
        # Gr√°fico
        fig, ax = plt.subplots(figsize=(7, 5))
        ax.plot(param_range, train_mean, color='blue', marker='o', markersize=5, label='Treino')
        ax.fill_between(param_range, train_mean - train_std, train_mean + train_std, alpha=0.15, color='blue')
    
        ax.plot(param_range, test_mean, color='red', marker='s', linestyle='--', markersize=5, label='Valida√ß√£o')
        ax.fill_between(param_range, test_mean - test_std, test_mean + test_std, alpha=0.15, color='red')
    
        ax.set_xlabel(xlabel)
        ax.set_ylabel('Acur√°cia')
        ax.set_title(title)
        ax.legend(loc='lower right')
        ax.grid(True)
        st.pyplot(fig)
    
        # Interpreta√ß√£o
        if np.argmax(test_mean) < len(test_mean) - 1 and test_mean[-1] < test_mean[np.argmax(test_mean)]:
            st.warning("‚ö†Ô∏è **Poss√≠vel overfitting**: a performance no conjunto de valida√ß√£o diminui ap√≥s um certo ponto.")
        else:
            st.success("‚úÖ **Sem sinais de overfitting claro**: a performance no teste acompanha a do treino.")
    
    except Exception as e:
        st.warning("N√£o foi poss√≠vel gerar a curva de perda. Modelo n√£o suporta valida√ß√£o direta.")
        
    # --- 6. PONTOS PARA DISCUSS√ÉO (L√∫dico e Educacional) ---
    st.markdown("### üí¨ Pontos para Reflex√£o")
    st.markdown("""
    #### üéØ 1. Precision vs Recall: Qual priorizar?
    - Se voc√™ √© **banco conservador**, quer alto **Recall** (capturar todos os inadimplentes).
    - Se quer **n√£o rejeitar bons clientes**, priorize **Precision**.
    - O **F1-Score** ajuda a equilibrar os dois.

    #### ‚ö†Ô∏è 2. Acur√°cia pode enganar!
    Se 95% dos clientes s√£o adimplentes, um modelo que diz "todos s√£o bons" ter√° 95% de acur√°cia... mas √© in√∫til.

    #### üìä 3. KS > 0.4 √© √≥timo, mas...
    ...verifique se o poder de separa√ß√£o √© est√°vel em subgrupos (idade, renda, regi√£o).

    #### üß© 4. E se o modelo for justo?
    Avalie se ele trata grupos sens√≠veis (g√™nero, ra√ßa) de forma equitativa. Isso √© **√©tica em IA**.

    #### üîÑ 5. E agora?
    Use essas m√©tricas para **ajustar o limiar de aprova√ß√£o** ou **melhorar o modelo**.
    """)

    # --- 7. RELAT√ìRIO DA AN√ÅLISE ---
st.markdown("### üìÑ Relat√≥rio da An√°lise de Valida√ß√£o")
st.info("Gere um resumo das m√©tricas e insights desta an√°lise para compartilhar ou documentar.")

# Prepara o conte√∫do do relat√≥rio
relatorio_texto = f"""
RELAT√ìRIO DE VALIDA√á√ÉO DO MODELO
=================================

üéØ Modelo: {modelo_tipo}
üéØ Vari√°vel-alvo: {target}
üéØ N√∫mero de vari√°veis preditoras: {len(features)}

üìä M√âTRICAS PRINCIPAIS
----------------------
Acur√°cia no Teste: {accuracy:.1%}
Precision: {precision:.1%}
Recall: {recall:.1%}
F1-Score: {f1:.1%}
AUC-ROC: {roc_auc:.2f}
KS M√°ximo: {ks_max:.2f}

üîç INTERPRETA√á√ÉO
----------------
- **Precision**: Entre os clientes classificados como inadimplentes, {precision:.1%} realmente s√£o.
- **Recall**: O modelo identificou {recall:.1%} dos verdadeiros inadimplentes.
- **AUC-ROC**: {'Excelente' if roc_auc > 0.9 else 'Bom' if roc_auc > 0.8 else 'Razo√°vel' if roc_auc > 0.7 else 'Fraco'} poder preditivo.
- **KS**: {'Excelente' if ks_max > 0.4 else 'Bom' if ks_max > 0.3 else 'Moderado'} separa√ß√£o entre bons e maus.

üìâ Overfitting
-------------
{'Poss√≠vel overfitting detectado.' if np.argmax(test_mean) < len(test_mean) - 1 and test_mean[-1] < test_mean[np.argmax(test_mean)] else 'Sem sinais claros de overfitting.'}

üìÖ Data: {pd.Timestamp.now().strftime('%d/%m/%Y %H:%M')}
"""

# Op√ß√µes de exporta√ß√£o
export_option = st.radio("Escolha o formato de exporta√ß√£o:", ["Texto (.txt)", "Copiar para √°rea de transfer√™ncia"])

if export_option == "Texto (.txt)":
    st.download_button(
        label="‚¨áÔ∏è Baixar Relat√≥rio (TXT)",
        data=relatorio_texto,
        file_name="relatorio_validacao_modelo.txt",
        mime="text/plain"
    )
else:
    st.code(relatorio_texto, language="text")
    st.info("Voc√™ pode copiar o texto acima com o bot√£o no canto superior direito.")
    # --- NAVEGA√á√ÉO ---
    st.markdown("---")
    st.page_link("pages/8_‚öôÔ∏è_Aperfeicoamento.py", label="‚û°Ô∏è Ir para Aperfei√ßoamento", icon="‚öôÔ∏è")

if __name__ == "__main__":
    main()

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report
import statsmodels.api as sm  # Para p-valores e significÃ¢ncia

def main():
    st.title("ðŸ¤– Modelagem Preditiva")
    st.markdown("Construa e avalie modelos de credit scoring com interpretaÃ§Ã£o clara.")

    if 'dados' not in st.session_state:
        st.warning("Dados nÃ£o encontrados! Complete a coleta primeiro.")
        st.page_link("pages/2_ðŸ“Š_Coleta_de_Dados.py", label="â†’ Coleta de Dados")
        return

    dados = st.session_state.dados.copy()

    st.subheader("âš™ï¸ ConfiguraÃ§Ã£o do Modelo")

    # SeleÃ§Ã£o da variÃ¡vel-alvo
    target = st.selectbox(
        "VariÃ¡vel Target (inadimplÃªncia):",
        options=dados.columns,
        index=None,
        placeholder="Escolha a variÃ¡vel de default"
    )

    if target is None or target not in dados.columns:
        st.stop()

    if target not in st.session_state:
        st.session_state.target = target

    # SeleÃ§Ã£o de variÃ¡veis preditoras
    features = st.multiselect(
        "VariÃ¡veis Preditivas:",
        options=[col for col in dados.columns if col != target],
        default=[col for col in dados.columns if col != target][:5]  # Sugere atÃ© 5
    )

    if len(features) == 0:
        st.warning("Selecione pelo menos uma variÃ¡vel preditora.")
        st.stop()

    # SeleÃ§Ã£o do modelo
    modelo_tipo = st.radio(
        "Escolha o modelo:",
        options=["RegressÃ£o LogÃ­stica", "Random Forest"],
        horizontal=True
    )
    st.info("ðŸ”¹ **RegressÃ£o LogÃ­stica**: InterpretaÃ§Ã£o clara, bom para modelos regulatÃ³rios.  
            ðŸ”¹ **Random Forest**: Alta performance, menos interpretÃ¡vel.")

    # Tratamento de variÃ¡veis categÃ³ricas
    st.markdown("#### ðŸ§± Tratamento de VariÃ¡veis CategÃ³ricas")
    cat_vars = dados[features].select_dtypes(include='object').columns.tolist()
    if len(cat_vars) > 0:
        st.write(f"VariÃ¡veis categÃ³ricas detectadas: `{', '.join(cat_vars)}`")
        encoding = st.radio(
            "Como deseja codificar variÃ¡veis categÃ³ricas?",
            options=["One-Hot Encoding (dummy)", "Label Encoding (numÃ©rico)"],
            horizontal=True
        )
    else:
        encoding = "Nenhuma"
        st.info("Nenhuma variÃ¡vel categÃ³rica encontrada.")

    # BotÃ£o de treinamento
    if st.button("ðŸš€ Treinar Modelo", type="primary"):
        with st.spinner("Treinando e avaliando o modelo..."):
            try:
                X = dados[features].copy()
                y = dados[target]

                # Aplica encoding
                if encoding == "One-Hot Encoding (dummy)" and len(cat_vars) > 0:
                    X = pd.get_dummies(X, columns=cat_vars, drop_first=True)
                elif encoding == "Label Encoding (numÃ©rico)" and len(cat_vars) > 0:
                    from sklearn.preprocessing import LabelEncoder
                    le = LabelEncoder()
                    for col in cat_vars:
                        X[col] = le.fit_transform(X[col].astype(str))

                # DivisÃ£o treino/teste
                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

                # Treina o modelo
                if modelo_tipo == "RegressÃ£o LogÃ­stica":
                    model = LogisticRegression(max_iter=1000, solver='liblinear')
                    model.fit(X_train, y_train)
                    y_pred = model.predict(X_test)

                    # Usar statsmodels para p-valores
                    X_train_sm = sm.add_constant(X_train)
                    model_sm = sm.Logit(y_train, X_train_sm).fit(disp=False)
                    p_values = model_sm.pvalues
                    significancia = p_values.reindex(X.columns, fill_value=np.nan)

                    # Armazena modelo e resultados
                    st.session_state.modelo = model
                    st.session_state.model_sm = model_sm
                    st.session_state.X_test = X_test
                    st.session_state.y_test = y_test
                    st.session_state.y_pred = y_pred
                    st.session_state.features = X.columns.tolist()

                    # MÃ©tricas
                    acuracia = model.score(X_test, y_test)
                    cm = confusion_matrix(y_test, y_pred)

                    st.success("âœ… Modelo de RegressÃ£o LogÃ­stica treinado com sucesso!")

                    # --- MATRIZ DE CONFUSÃƒO ---
                    st.markdown("### ðŸ“Š Matriz de ConfusÃ£o")
                    st.info("""
                    Mostra quantos casos foram classificados correta e incorretamente:
                    - **Verdadeiros Positivos (VP)**: Inadimplentes corretamente identificados.
                    - **Falsos Positivos (FP)**: Adimplentes classificados como inadimplentes.
                    - **Verdadeiros Negativos (VN)**: Adimplentes corretamente identificados.
                    - **Falsos Negativos (FN)**: Inadimplentes nÃ£o detectados (pior erro).
                    """)
                    fig, ax = plt.subplots(figsize=(5, 4))
                    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,
                                xticklabels=['Adimplente (0)', 'Inadimplente (1)'],
                                yticklabels=['Adimplente (0)', 'Inadimplente (1)'])
                    ax.set_ylabel('Real')
                    ax.set_xlabel('Previsto')
                    ax.set_title('Matriz de ConfusÃ£o')
                    st.pyplot(fig)

                    # --- EXPRESSÃƒO ALGÃ‰BRICA ---
                    st.markdown("### ðŸ§® ExpressÃ£o do Modelo (Score Linear)")
                    st.info("""
                    O modelo calcula um **logit** (score bruto) com base nos coeficientes:
                    `logit = Î²â‚€ + Î²â‚Â·xâ‚ + Î²â‚‚Â·xâ‚‚ + ...`
                    Depois converte para probabilidade com a funÃ§Ã£o logÃ­stica:
                    `P(default) = 1 / (1 + e^(-logit))`
                    """)
                    coef_intercept = model.intercept_[0]
                    terms = [f"{coef_intercept:.4f}"]
                    for feat, coef in zip(X.columns, model.coef_[0]):
                        sign = "+" if coef >= 0 else "-"
                        terms.append(f"{sign} {abs(coef):.4f}Â·{feat}")
                    formula = " + ".join(terms)
                    st.latex(f"\\text{{logit}} = {formula}")

                    # --- TABELA DE COEFICIENTES ---
                    st.markdown("### ðŸ“‹ Tabela de Coeficientes e SignificÃ¢ncia")
                    st.info("""
                    - **Coeficiente**: impacto da variÃ¡vel no log-odds.
                    - **P-valor**: indica se o efeito Ã© estatisticamente significativo (geralmente < 0.05).
                    - **SignificÃ¢ncia**: *** (p<0.001), ** (p<0.01), * (p<0.05), . (p<0.1)
                    """)
                    coef_df = pd.DataFrame({
                        'VariÃ¡vel': ['Intercept'] + X.columns.tolist(),
                        'Coeficiente': [model.intercept_[0]] + model.coef_[0].tolist(),
                        'P-valor': [p_values['const']] + significancia.tolist()
                    })
                    coef_df['SignificÃ¢ncia'] = coef_df['P-valor'].apply(
                        lambda p: '***' if p < 0.001 else '**' if p < 0.01 else '*' if p < 0.05 else '.' if p < 0.1 else ''
                    )
                    coef_df['Coeficiente'] = coef_df['Coeficiente'].round(4)
                    coef_df['P-valor'] = coef_df['P-valor'].round(4)

                    st.dataframe(
                        coef_df.style.format({
                            'Coeficiente': '{:.4f}',
                            'P-valor': '{:.4f}'
                        }).background_gradient(cmap='RdYlGn', subset=['Coeficiente'], low=1, high=1)
                    )

                    # MÃ©trica final
                    st.metric("AcurÃ¡cia no Teste", f"{acuracia:.1%}")

                elif modelo_tipo == "Random Forest":
                    model = RandomForestClassifier(n_estimators=100, random_state=42)
                    model.fit(X_train, y_train)
                    y_pred = model.predict(X_test)

                    st.session_state.modelo = model
                    st.session_state.X_test = X_test
                    st.session_state.y_test = y_test
                    st.session_state.y_pred = y_pred
                    st.session_state.features = X.columns.tolist()

                    acuracia = model.score(X_test, y_test)
                    cm = confusion_matrix(y_test, y_pred)

                    st.success("âœ… Modelo Random Forest treinado com sucesso!")

                    # --- MATRIZ DE CONFUSÃƒO ---
                    st.markdown("### ðŸ“Š Matriz de ConfusÃ£o")
                    st.info("""
                    Mesma interpretaÃ§Ã£o que na regressÃ£o logÃ­stica. Avalia a qualidade das previsÃµes.
                    """)
                    fig, ax = plt.subplots(figsize=(5, 4))
                    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,
                                xticklabels=['Adimplente (0)', 'Inadimplente (1)'],
                                yticklabels=['Adimplente (0)', 'Inadimplente (1)'])
                    ax.set_ylabel('Real')
                    ax.set_xlabel('Previsto')
                    ax.set_title('Matriz de ConfusÃ£o')
                    st.pyplot(fig)

                    # --- IMPORTÃ‚NCIA DAS VARIÃVEIS ---
                    st.markdown("### ðŸ” ImportÃ¢ncia das VariÃ¡veis")
                    st.info("""
                    Mostra quais variÃ¡veis mais contribuÃ­ram para as decisÃµes do modelo.
                    Ãštil para explicabilidade, mesmo que o modelo seja menos interpretÃ¡vel.
                    """)
                    importances = model.feature_importances_
                    importance_df = pd.DataFrame({
                        'VariÃ¡vel': X.columns,
                        'ImportÃ¢ncia': importances
                    }).sort_values('ImportÃ¢ncia', ascending=True)

                    fig, ax = plt.subplots(figsize=(6, 0.35 * len(importance_df)))
                    ax.barh(importance_df['VariÃ¡vel'], importance_df['ImportÃ¢ncia'], color='teal')
                    ax.set_title("ImportÃ¢ncia das VariÃ¡veis (Random Forest)")
                    st.pyplot(fig)

                    st.metric("AcurÃ¡cia no Teste", f"{acuracia:.1%}")

            except Exception as e:
                st.error(f"Erro ao treinar o modelo: {str(e)}")

    # --- NAVEGAÃ‡ÃƒO ---
    st.markdown("---")
    st.page_link("pages/7_âœ…_Analise_e_Validacao.py", label="âž¡ï¸ Ir para AnÃ¡lise e ValidaÃ§Ã£o", icon="âœ…")

if __name__ == "__main__":
    main()

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
from sklearn.preprocessing import LabelEncoder
import statsmodels.api as sm
import io

def main():
    st.title("ü§ñ Modelagem Preditiva")
    st.markdown("Construa e avalie modelos de credit scoring com interpreta√ß√£o clara.")

    if 'dados' not in st.session_state:
        st.warning("Dados n√£o encontrados! Complete a coleta primeiro.")
        st.page_link("pages/2_üìä_Coleta_de_Dados.py", label="‚Üí Coleta de Dados")
        return

    dados = st.session_state.dados.copy()

    st.subheader("‚öôÔ∏è Configura√ß√£o do Modelo")

    # --- 1. SELE√á√ÉO E VALIDA√á√ÉO DA VARI√ÅVEL-ALVO (Y) ---
    st.markdown("### üîç Defina a Vari√°vel-Alvo (Default)")
    target = st.selectbox(
        "Selecione a coluna que indica **inadimpl√™ncia**:",
        options=dados.columns,
        index=None,
        placeholder="Escolha a vari√°vel de default",
        key="target_select"  # ‚Üê mant√©m estado
    )
    
    if target not in dados.columns:
        st.error("ALERTA: vari√°vel-alvo inv√°lida ou indefinida.")
        return
    
    y_data = dados[target].dropna()
    if len(y_data) == 0:
        st.error(f"A coluna `{target}` est√° vazia.")
        return
    
    valores_unicos = pd.Series(y_data.unique()).dropna().tolist()
    try:
        # Tenta ordenar apenas valores num√©ricos
        valores_numericos = [x for x in valores_unicos if isinstance(x, (int, float))]
        valores_unicos = sorted(valores_numericos) if valores_numericos else valores_unicos
    except:
        pass
    
    # Verificar se √© bin√°ria (0/1)
    if set(valores_unicos) != {0, 1}:
        st.warning(f"""
        ‚ö†Ô∏è A vari√°vel `{target}` n√£o est√° no formato 0/1.  
        Valores encontrados: {valores_unicos}
        """)
    
        st.markdown("#### üîß Mapeie os valores para 0 (adimplente) e 1 (inadimplente)")
        col1, col2 = st.columns(2)
    
        with col1:
            valor_bom = st.selectbox(
                "Valor que representa **adimplente (0)**",
                options=valores_unicos,
                key="valor_bom_select"  # ‚Üê estado persistente
            )
    
        with col2:
            # Remove o valor escolhido como "bom" das op√ß√µes para "mau"
            opcoes_maus = [v for v in valores_unicos if v != valor_bom]
            valor_mau = st.selectbox(
                "Valor que representa **inadimplente (1)**",
                options=opcoes_maus,
                key="valor_mau_select"  # ‚Üê estado persistente
            )
    
        # Bot√£o para aplicar o mapeamento
        if st.button("‚úÖ Aplicar Mapeamento", key="btn_aplicar_mapeamento"):
            if valor_bom == valor_mau:
                st.error("Erro: os valores para 'bom' e 'mau' devem ser diferentes.")
            else:
                try:
                    # Mapeia os valores
                    y_mapped = dados[target].map({valor_bom: 0, valor_mau: 1})
                    
                    # Verifica se houve falha no mapeamento (valores n√£o mapeados)
                    if y_mapped.isnull().any():
                        st.error(f"Erro: alguns valores n√£o foram mapeados corretamente. Verifique os dados.")
                    else:
                        # Atualiza os dados
                        dados_atualizados = dados.copy()
                        dados_atualizados[target] = y_mapped
                        st.session_state.dados = dados_atualizados
                        st.session_state.target = target
                        st.success(f"‚úÖ `{target}` foi convertida para 0 (adimplente) e 1 (inadimplente).")
                        st.rerun()  # ‚Üê recarrega para refletir a mudan√ßa
                except Exception as e:
                    st.error(f"Erro ao aplicar mapeamento: {e}")
    
    else:
        st.success(f"‚úÖ `{target}` j√° est√° no formato 0/1.")
        st.session_state.target = target

    # --- 2. Sele√ß√£o de vari√°veis preditoras ---
    st.markdown("### üìä Dados que ser√£o usados no modelo")
    features = st.multiselect(
        "Vari√°veis Preditivas:",
        options=[col for col in dados.columns if col != target],
        default=[col for col in dados.columns if col != target][:5]
    )

    if len(features) == 0:
        st.warning("Selecione pelo menos uma vari√°vel preditora.")
        st.stop()

    # --- 3. Mostrar DataFrame antes do modelo ---
    st.info("Abaixo est√£o as vari√°veis preditoras (X) e a vari√°vel-alvo (y) que ser√£o usadas no treinamento.")
    X_preview = dados[features].head(10)
    y_preview = dados[target].head(10)
    preview = pd.concat([X_preview, y_preview], axis=1)
    st.dataframe(preview)

    # --- 4. Escolha do modelo ---
    modelo_tipo = st.radio(
        "Escolha o modelo:",
        options=["Regress√£o Log√≠stica", "Random Forest"],
        horizontal=True
    )
    st.info("""üîπ **Regress√£o Log√≠stica**: Interpreta√ß√£o clara, ideal para modelos regulat√≥rios.  
            üîπ **Random Forest**: Alta performance, menos interpret√°vel.""")

    # --- 5. Bot√£o de treinamento ---
    if st.button("üöÄ Treinar Modelo", type="primary"):
        with st.spinner("Preparando dados e treinando o modelo..."):
            try:
                X = dados[features].copy()
                y = dados[target]

                # --- Tratamento de vari√°veis categ√≥ricas (feito aqui, n√£o antes) ---
                cat_vars = X.select_dtypes(include='object').columns.tolist()

                if len(cat_vars) > 0:
                    st.info(f"üîç Detectadas {len(cat_vars)} vari√°veis categ√≥ricas: `{', '.join(cat_vars)}`. Aplicando tratamento...")
                    
                    # Pergunta como tratar cada uma (pode ser melhorado com interface, mas funcional)
                    encoding_choice = {}
                    for var in cat_vars:
                        choice = st.radio(
                            f"Tratamento para `{var}`:",
                            options=["One-Hot Encoding", "Label Encoding"],
                            key=f"encoding_{var}",
                            horizontal=True
                        )
                        encoding_choice[var] = choice

                    # Aplica tratamento
                    for var in cat_vars:
                        if encoding_choice[var] == "One-Hot Encoding":
                            dummies = pd.get_dummies(X[var], prefix=var, drop_first=True)
                            X = pd.concat([X.drop(columns=[var]), dummies], axis=1)
                            st.success(f"‚úÖ `{var}`: One-Hot Encoding aplicado.")
                        elif encoding_choice[var] == "Label Encoding":
                            X[var] = X[var].astype('category').cat.codes
                            st.success(f"‚úÖ `{var}`: Label Encoding aplicado.")
                else:
                    st.info("‚úÖ Nenhuma vari√°vel categ√≥rica encontrada. Continuando com vari√°veis num√©ricas.")

                # --- Convers√£o final para num√©rico ---
                for col in X.columns:
                    if X[col].dtype == 'object':
                        try:
                            X[col] = pd.to_numeric(X[col], errors='coerce')
                            st.warning(f"‚ö†Ô∏è Coluna `{col}` convertida para num√©rico (com coer√ß√£o).")
                        except:
                            st.error(f"Erro ao converter `{col}` para num√©rico.")
                            st.stop()

                # --- Preenche valores faltantes ---
                if X.isnull().any().any():
                    st.warning("‚ö†Ô∏è Dados faltantes encontrados. Preenchendo com m√©dia.")
                    X = X.fillna(X.mean(numeric_only=True))

                # --- Garante tipo num√©rico ---
                X = X.astype(float)

                # --- Divis√£o treino/teste ---
                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

                # --- Treinamento do modelo ---
                if modelo_tipo == "Regress√£o Log√≠stica":
                    model = LogisticRegression(max_iter=1000, solver='liblinear')
                    model.fit(X_train, y_train)
                    y_pred = model.predict(X_test)

                    # Statsmodels para p-valores
                    X_train_sm = sm.add_constant(X_train)
                    model_sm = sm.Logit(y_train, X_train_sm).fit(disp=False)
                    p_values = model_sm.pvalues[1:]

                    st.session_state.modelo = model
                    st.session_state.model_sm = model_sm
                    st.session_state.X_test = X_test
                    st.session_state.y_test = y_test
                    st.session_state.y_pred = y_pred
                    st.session_state.features = X.columns.tolist()

                    acuracia = model.score(X_test, y_test)
                    cm = confusion_matrix(y_test, y_pred)

                    st.success("‚úÖ Modelo de Regress√£o Log√≠stica treinado!")

                    # --- MATRIZ DE CONFUS√ÉO ---
                    st.markdown("### üìä Matriz de Confus√£o")
                    st.info("""Ajuda a entender os erros do modelo.
                    Mostra quantos casos foram classificados correta e incorretamente:
                    - **Verdadeiros Positivos (VP)**: Inadimplentes corretamente identificados.
                    - **Falsos Positivos (FP)**: Adimplentes classificados como inadimplentes.
                    - **Verdadeiros Negativos (VN)**: Adimplentes corretamente identificados.
                    - **Falsos Negativos (FN)**: Inadimplentes n√£o detectados (pior erro).
                    """)
                    
                    fig, ax = plt.subplots(figsize=(5, 4))
                    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,
                                xticklabels=['Adimplente', 'Inadimplente'],
                                yticklabels=['Adimplente', 'Inadimplente'])
                    ax.set_xlabel('Previsto')
                    ax.set_ylabel('Real')
                    st.pyplot(fig)

                    # --- EXPRESS√ÉO ALG√âBRICA ---
                    st.markdown("### üßÆ Express√£o do Modelo (Logit)")
                    coef_intercept = model.intercept_[0]
                    terms = [f"{coef_intercept:.4f}"]
                    symbols = [f"X_{i+1}" for i in range(len(X.columns))]
                    # --- EXPRESS√ÉO ALG√âBRICA COM NOTA√á√ÉO PADR√ÉO ---
                    st.info("""
                    A probabilidade de inadimpl√™ncia √© calculada a partir do **logit**, dado por:
                    `logit = Œ≤‚ÇÄ + Œ≤‚ÇÅ¬∑X‚ÇÅ + Œ≤‚ÇÇ¬∑X‚ÇÇ + ... + Œ≤‚Çñ¬∑X‚Çñ`
                    Este score linear √© convertido em probabilidade com a fun√ß√£o log√≠stica:
                    `P(default) = 1 / (1 + e^(-logit))`
                    """)
                                        
                    # Monta os termos com sinais
                    for symbols, coef in zip(symbols, model.coef_[0]):
                        sinal = "+" if coef >= 0 else "-"
                        terms.append(f"{sinal} {abs(coef):.2f} \\cdot {symbols}")
                    
                    # Monta a f√≥rmula em LaTeX
                    formula = " ".join(terms)
                    st.latex(f"\\text{{logit}} = {formula}")
                    
                    # --- TABELA DE LEGENDA DAS VARI√ÅVEIS ---
                    st.warning("""Cada s√≠mbolo $$X_i$$ representa uma vari√°vel preditora do modelo. Mais especificamente:
                        # Gera a lista de legenda em LaTeX
                        legenda_latex = []
                        for i, var in enumerate(X.columns):
                            # Escapa caracteres problem√°ticos (como _)
                            var_escapado = var.replace('_', r'\_')
                            legenda_latex.append(rf"X_{{{i+1}}} = \text{{{var_escapado}}}")
                        
                        # Junta com quebra de linha
                        legenda_str = r" \\ ".join(legenda_latex)
                        st.latex(legenda_str)
                    """)
                    # --- TABELA DE COEFICIENTES ---
                    st.markdown("### üìã Coeficientes e Signific√¢ncia")
                    st.info("""Coeficiente: impacto no log-odds. P-valor: signific√¢ncia estat√≠stica. 
                            Nota: N√≠veis de Signific√¢ncia s√£o importantes para validar estatisticamente a import√¢ncia da vari√°vel no modelo. No caso, *** √© muito alta (praticamente 0%), ** √© alta (1%) e * √© significante a 5%. """)
                    coef_df = pd.DataFrame({
                        'Vari√°vel': X.columns,
                        'Coeficiente': model.coef_[0],
                        'P-valor': p_values.values
                    }).round(4)
                    coef_df['Signific√¢ncia'] = coef_df['P-valor'].apply(
                        lambda p: '***' if p < 0.001 else '**' if p < 0.01 else '*' if p < 0.05 else ''
                    )
                    st.dataframe(coef_df.style.background_gradient(cmap='RdYlGn', subset=['Coeficiente']))

                    st.metric("Acur√°cia no Teste", f"{acuracia:.1%}")

                elif modelo_tipo == "Random Forest":
                    model = RandomForestClassifier(n_estimators=100, random_state=42)
                    model.fit(X_train, y_train)
                    y_pred = model.predict(X_test)

                    st.session_state.modelo = model
                    st.session_state.X_test = X_test
                    st.session_state.y_test = y_test
                    st.session_state.y_pred = y_pred
                    st.session_state.features = X.columns.tolist()

                    acuracia = model.score(X_test, y_test)
                    cm = confusion_matrix(y_test, y_pred)

                    st.success("‚úÖ Modelo Random Forest treinado!")

                    # --- MATRIZ DE CONFUS√ÉO ---
                    st.markdown("### üìä Matriz de Confus√£o")
                    fig, ax = plt.subplots(figsize=(5, 4))
                    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,
                                xticklabels=['Adimplente', 'Inadimplente'],
                                yticklabels=['Adimplente', 'Inadimplente'])
                    ax.set_xlabel('Previsto')
                    ax.set_ylabel('Real')
                    st.pyplot(fig)

                    # --- IMPORT√ÇNCIA DAS VARI√ÅVEIS ---
                    st.markdown("### üîç Import√¢ncia das Vari√°veis")
                    importances = model.feature_importances_
                    importance_df = pd.DataFrame({'Vari√°vel': X.columns, 'Import√¢ncia': importances}).sort_values('Import√¢ncia', ascending=True)
                    fig, ax = plt.subplots(figsize=(6, 0.35 * len(importance_df)))
                    ax.barh(importance_df['Vari√°vel'], importance_df['Import√¢ncia'], color='teal')
                    ax.set_title("Import√¢ncia das Vari√°veis (Random Forest)")
                    st.pyplot(fig)

                    st.metric("Acur√°cia no Teste", f"{acuracia:.1%}")

            except Exception as e:
                st.error(f"Erro ao treinar o modelo: {e}")

    # --- NAVEGA√á√ÉO ---
    st.markdown("---")
    st.page_link("pages/7_‚úÖ_Analise_e_Validacao.py", label="‚û°Ô∏è Ir para An√°lise e Valida√ß√£o", icon="‚úÖ")

if __name__ == "__main__":
    main()

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
from sklearn.preprocessing import LabelEncoder
import statsmodels.api as sm
import io

def main():
    st.title("ðŸ¤– Modelagem Preditiva")
    st.markdown("Construa e avalie modelos de credit scoring com interpretaÃ§Ã£o clara.")

    if 'dados' not in st.session_state:
        st.warning("Dados nÃ£o encontrados! Complete a coleta primeiro.")
        st.page_link("pages/2_ðŸ“Š_Coleta_de_Dados.py", label="â†’ Coleta de Dados")
        return

    dados = st.session_state.dados.copy()

    st.subheader("âš™ï¸ ConfiguraÃ§Ã£o do Modelo")

    # --- 1. SeleÃ§Ã£o da variÃ¡vel-alvo ---
    target = st.selectbox(
        "VariÃ¡vel Target (inadimplÃªncia):",
        options=dados.columns,
        index=None,
        placeholder="Escolha a variÃ¡vel de default"
    )

    if target is None or target not in dados.columns:
        st.stop()

    # --- 2. SeleÃ§Ã£o de variÃ¡veis preditoras ---
    features = st.multiselect(
        "VariÃ¡veis Preditivas:",
        options=[col for col in dados.columns if col != target],
        default=[col for col in dados.columns if col != target][:5]
    )

    if len(features) == 0:
        st.warning("Selecione pelo menos uma variÃ¡vel preditora.")
        st.stop()

    # --- 3. Mostrar DataFrame antes do modelo ---
    st.markdown("### ðŸ“Š Dados que serÃ£o usados no modelo")
    st.info("Abaixo estÃ£o as variÃ¡veis preditoras (X) e a variÃ¡vel-alvo (y) que serÃ£o usadas no treinamento.")
    X_preview = dados[features].head(10)
    y_preview = dados[target].head(10)
    preview = pd.concat([X_preview, y_preview], axis=1)
    st.dataframe(preview)

    # --- 4. Escolha do modelo ---
    modelo_tipo = st.radio(
        "Escolha o modelo:",
        options=["RegressÃ£o LogÃ­stica", "Random Forest"],
        horizontal=True
    )
    st.info("""ðŸ”¹ **RegressÃ£o LogÃ­stica**: InterpretaÃ§Ã£o clara, ideal para modelos regulatÃ³rios.  
            ðŸ”¹ **Random Forest**: Alta performance, menos interpretÃ¡vel.""")

    # --- 5. BotÃ£o de treinamento ---
    if st.button("ðŸš€ Treinar Modelo", type="primary"):
        with st.spinner("Preparando dados e treinando o modelo..."):
            try:
                X = dados[features].copy()
                y = dados[target]

                # --- Tratamento de variÃ¡veis categÃ³ricas (feito aqui, nÃ£o antes) ---
                cat_vars = X.select_dtypes(include='object').columns.tolist()

                if len(cat_vars) > 0:
                    st.info(f"ðŸ” Detectadas {len(cat_vars)} variÃ¡veis categÃ³ricas: `{', '.join(cat_vars)}`. Aplicando tratamento...")
                    
                    # Pergunta como tratar cada uma (pode ser melhorado com interface, mas funcional)
                    encoding_choice = {}
                    for var in cat_vars:
                        choice = st.radio(
                            f"Tratamento para `{var}`:",
                            options=["One-Hot Encoding", "Label Encoding"],
                            key=f"encoding_{var}",
                            horizontal=True
                        )
                        encoding_choice[var] = choice

                    # Aplica tratamento
                    for var in cat_vars:
                        if encoding_choice[var] == "One-Hot Encoding":
                            dummies = pd.get_dummies(X[var], prefix=var, drop_first=True)
                            X = pd.concat([X.drop(columns=[var]), dummies], axis=1)
                            st.success(f"âœ… `{var}`: One-Hot Encoding aplicado.")
                        elif encoding_choice[var] == "Label Encoding":
                            X[var] = X[var].astype('category').cat.codes
                            st.success(f"âœ… `{var}`: Label Encoding aplicado.")
                else:
                    st.info("âœ… Nenhuma variÃ¡vel categÃ³rica encontrada. Continuando com variÃ¡veis numÃ©ricas.")

                # --- ConversÃ£o final para numÃ©rico ---
                for col in X.columns:
                    if X[col].dtype == 'object':
                        try:
                            X[col] = pd.to_numeric(X[col], errors='coerce')
                            st.warning(f"âš ï¸ Coluna `{col}` convertida para numÃ©rico (com coerÃ§Ã£o).")
                        except:
                            st.error(f"Erro ao converter `{col}` para numÃ©rico.")
                            st.stop()

                # --- Preenche valores faltantes ---
                if X.isnull().any().any():
                    st.warning("âš ï¸ Dados faltantes encontrados. Preenchendo com mÃ©dia.")
                    X = X.fillna(X.mean(numeric_only=True))

                # --- Garante tipo numÃ©rico ---
                X = X.astype(float)

                # --- DivisÃ£o treino/teste ---
                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

                # --- Treinamento do modelo ---
                if modelo_tipo == "RegressÃ£o LogÃ­stica":
                    model = LogisticRegression(max_iter=1000, solver='liblinear')
                    model.fit(X_train, y_train)
                    y_pred = model.predict(X_test)

                    # Statsmodels para p-valores
                    X_train_sm = sm.add_constant(X_train)
                    model_sm = sm.Logit(y_train, X_train_sm).fit(disp=False)
                    p_values = model_sm.pvalues[1:]

                    st.session_state.modelo = model
                    st.session_state.model_sm = model_sm
                    st.session_state.X_test = X_test
                    st.session_state.y_test = y_test
                    st.session_state.y_pred = y_pred
                    st.session_state.features = X.columns.tolist()

                    acuracia = model.score(X_test, y_test)
                    cm = confusion_matrix(y_test, y_pred)

                    st.success("âœ… Modelo de RegressÃ£o LogÃ­stica treinado!")

                    # --- MATRIZ DE CONFUSÃƒO ---
                    st.markdown("### ðŸ“Š Matriz de ConfusÃ£o")
                    st.info("Mostra VP, VN, FP, FN. Ajuda a entender os erros do modelo.")
                    fig, ax = plt.subplots(figsize=(5, 4))
                    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,
                                xticklabels=['Adimplente', 'Inadimplente'],
                                yticklabels=['Adimplente', 'Inadimplente'])
                    ax.set_xlabel('Previsto')
                    ax.set_ylabel('Real')
                    st.pyplot(fig)

                    # --- EXPRESSÃƒO ALGÃ‰BRICA ---
                    st.markdown("### ðŸ§® ExpressÃ£o do Modelo (Logit)")
                    coef_intercept = model.intercept_[0]
                    terms = [f"{coef_intercept:.4f}"]
                    for feat, coef in zip(X.columns, model.coef_[0]):
                        sign = "+" if coef >= 0 else "-"
                        terms.append(f"{sign} {abs(coef):.4f}Â·{feat}")
                    formula = " + ".join(terms)
                    st.latex(f"\\text{{logit}} = {formula}")

                    # --- TABELA DE COEFICIENTES ---
                    st.markdown("### ðŸ“‹ Coeficientes e SignificÃ¢ncia")
                    st.info("Coeficiente: impacto no log-odds. P-valor: significÃ¢ncia estatÃ­stica.")
                    coef_df = pd.DataFrame({
                        'VariÃ¡vel': X.columns,
                        'Coeficiente': model.coef_[0],
                        'P-valor': p_values.values
                    }).round(4)
                    coef_df['SignificÃ¢ncia'] = coef_df['P-valor'].apply(
                        lambda p: '***' if p < 0.001 else '**' if p < 0.01 else '*' if p < 0.05 else ''
                    )
                    st.dataframe(coef_df.style.background_gradient(cmap='RdYlGn', subset=['Coeficiente']))

                    st.metric("AcurÃ¡cia no Teste", f"{acuracia:.1%}")

                elif modelo_tipo == "Random Forest":
                    model = RandomForestClassifier(n_estimators=100, random_state=42)
                    model.fit(X_train, y_train)
                    y_pred = model.predict(X_test)

                    st.session_state.modelo = model
                    st.session_state.X_test = X_test
                    st.session_state.y_test = y_test
                    st.session_state.y_pred = y_pred
                    st.session_state.features = X.columns.tolist()

                    acuracia = model.score(X_test, y_test)
                    cm = confusion_matrix(y_test, y_pred)

                    st.success("âœ… Modelo Random Forest treinado!")

                    # --- MATRIZ DE CONFUSÃƒO ---
                    st.markdown("### ðŸ“Š Matriz de ConfusÃ£o")
                    fig, ax = plt.subplots(figsize=(5, 4))
                    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,
                                xticklabels=['Adimplente', 'Inadimplente'],
                                yticklabels=['Adimplente', 'Inadimplente'])
                    ax.set_xlabel('Previsto')
                    ax.set_ylabel('Real')
                    st.pyplot(fig)

                    # --- IMPORTÃ‚NCIA DAS VARIÃVEIS ---
                    st.markdown("### ðŸ” ImportÃ¢ncia das VariÃ¡veis")
                    importances = model.feature_importances_
                    importance_df = pd.DataFrame({'VariÃ¡vel': X.columns, 'ImportÃ¢ncia': importances}).sort_values('ImportÃ¢ncia', ascending=True)
                    fig, ax = plt.subplots(figsize=(6, 0.35 * len(importance_df)))
                    ax.barh(importance_df['VariÃ¡vel'], importance_df['ImportÃ¢ncia'], color='teal')
                    ax.set_title("ImportÃ¢ncia das VariÃ¡veis (Random Forest)")
                    st.pyplot(fig)

                    st.metric("AcurÃ¡cia no Teste", f"{acuracia:.1%}")

            except Exception as e:
                st.error(f"Erro ao treinar o modelo: {e}")

    # --- NAVEGAÃ‡ÃƒO ---
    st.markdown("---")
    st.page_link("pages/7_âœ…_Analise_e_Validacao.py", label="âž¡ï¸ Ir para AnÃ¡lise e ValidaÃ§Ã£o", icon="âœ…")

if __name__ == "__main__":
    main()
